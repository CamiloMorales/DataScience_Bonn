{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame, read_csv\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../ToolBox')\n",
    "\n",
    "import CrossValidation, MLP, Helper, ZScore, RandomForest\n",
    "\n",
    "import os, sys\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saved_train_data = open('pre_processed_data/train_preprocessed.pkl', 'rb')\n",
    "normalized_train_data = cPickle.load(saved_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saved_test_data = open('pre_processed_data/test_preprocessed.pkl', 'rb')\n",
    "normalized_test_data = cPickle.load(saved_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json loaded\n",
      "(26729,)\n",
      "(26729, 1)\n",
      "[[ 4.         -0.8450405  -0.870233   -0.39585635 -0.46244225 -0.82232481]\n",
      " [ 3.          1.18361819  0.04882579 -0.39585635 -0.45789322 -0.78753173]\n",
      " [ 1.         -0.8450405  -0.870233   -0.05872967 -0.45334423 -0.75273871]\n",
      " ..., \n",
      " [ 1.         -0.8450405  -0.870233    0.6155237   0.61567223 -0.09167068]\n",
      " [ 5.          1.18361819  0.9678846  -0.70712125 -0.45789322 -0.47439426]\n",
      " [ 5.          1.18361819  0.9678846  -0.39585635 -0.45789322  0.29105291]]\n",
      "(26729, 5)\n",
      "(26729, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../ToolBox/RandomForest.py:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(data['x'], data['y'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04993139,  0.00644955,  0.13598017,  0.27240203,  0.53523686],\n",
       "       [ 0.53688271,  0.00130972,  0.02155532,  0.27378987,  0.16646238],\n",
       "       [ 0.36839739,  0.00336257,  0.02869202,  0.12656538,  0.47298264],\n",
       "       ..., \n",
       "       [ 0.02057382,  0.00834541,  0.07106239,  0.01961555,  0.88040283],\n",
       "       [ 0.34489376,  0.00136266,  0.05343579,  0.41758704,  0.18272074],\n",
       "       [ 0.0245253 ,  0.00522979,  0.31189475,  0.37088469,  0.28746547]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"../ToolBox/params.json\") as data_file:\n",
    "    params = yaml.safe_load(data_file)\n",
    "print 'json loaded'\n",
    "labels = normalized_train_data[:,0]\n",
    "print labels.shape\n",
    "labels = np.reshape(labels, [labels.shape[0], 1])\n",
    "print labels.shape\n",
    "labels = np.subtract(np.array(labels), 1)\n",
    "\n",
    "print normalized_train_data\n",
    "\n",
    "data_dict = dict({'x':normalized_train_data[:,1:], 'y':Helper.convert_one_hot_encoding(labels,params['MLPandRF']['MLP']['output-dim'])})\n",
    "\n",
    "print data_dict['y'].shape\n",
    "\n",
    "mlp = MLP.init(params['MLPandRF']['MLP'])\n",
    "mlp['train'](data_dict)\n",
    "\n",
    "data_dict['x'] = mlp['predict'](data_dict['x'], 1)\n",
    "data_dict['y'] = labels\n",
    "\n",
    "print np.array(data_dict['x']).shape\n",
    "\n",
    "test_transformed = mlp['predict'](normalized_test_data, 1)\n",
    "\n",
    "rf = RandomForest.init(params['MLPandRF']['RF'])\n",
    "model = rf['train'](data_dict)\n",
    "result_dict = rf['predict_probabilities'](test_transformed, model)\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11456, 5)\n"
     ]
    }
   ],
   "source": [
    "print result_dict.shape\n",
    "\n",
    "lis = []\n",
    "lis.append(\"ID,Adoption,Died,Euthanasia,Return_to_owner,Transfer\")\n",
    "\n",
    "for idx, z in enumerate(result_dict):\n",
    "    string = str(idx+1)\n",
    "    for prob in z:\n",
    "        string += ',' + str(prob)\n",
    "    lis.append(string)\n",
    "\n",
    "lis = np.array(lis)\n",
    "np.savetxt('result_shelter_animal_outcomes.csv', lis, fmt='%s', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
